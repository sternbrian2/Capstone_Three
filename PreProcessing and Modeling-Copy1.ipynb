{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7efba373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a051a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "\n",
    "order_total = pd.read_csv('order_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0049b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#order_total.head()\n",
    "order_total = order_total.drop(columns = ['product_name','aisle','department','order_number','order_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f892d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = order_total['reordered']\n",
    "order_total = order_total.drop(columns = ['reordered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "969661c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "def Labelencoder_feature(x):\n",
    "    le=LabelEncoder()\n",
    "    x=le.fit_transform(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e2659eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_total=order_total.apply(Labelencoder_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fac2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17b401ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b4483c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(order_total, target, test_size=0.2, random_state=42)\n",
    "scaler_x = MinMaxScaler((-1,1))\n",
    "X_train = scaler_x.fit_transform(X_train)\n",
    "X_test = scaler_x.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcbc866d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_parameter</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.674274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.674176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.674181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.674179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.674179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.674179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_parameter  Accuracy\n",
       "0        0.001  0.674274\n",
       "1        0.010  0.674176\n",
       "2        0.100  0.674181\n",
       "3        1.000  0.674179\n",
       "4       10.000  0.674179\n",
       "5      100.000  0.674179"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear Regression\n",
    "\n",
    "C_param_range = [0.001,0.01,0.1,1,10,100]\n",
    "\n",
    "table = pd.DataFrame(columns = ['C_parameter','Accuracy'])\n",
    "table['C_parameter'] = C_param_range\n",
    "\n",
    "j = 0\n",
    "for i in C_param_range:\n",
    "    \n",
    "    # Apply logistic regression model to training data\n",
    "    Logreg = LogisticRegression(penalty = 'l2', C = i,random_state = 42)\n",
    "    Logreg.fit(X_train,y_train)\n",
    "    \n",
    "    # Predict using model\n",
    "    y_pred_lr = Logreg.predict(X_test)\n",
    "    \n",
    "    # Saving accuracy score in table\n",
    "    table.iloc[j,1] = accuracy_score(y_test,y_pred_lr)\n",
    "    j += 1\n",
    "    \n",
    "table   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b03f6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 190314  384901]\n",
      " [ 135738 1047511]]\n",
      "0.7039239927573154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(bootstrap=True,n_estimators=100,criterion='entropy')\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict_rf = rf.predict(X_test)\n",
    "\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict_rf)\n",
    "print(cnf_matrix)\n",
    "Accuracy_rf=rf.score(X_test,y_test)\n",
    "print(Accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23bcf160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68222615 0.68097095 0.6834969  0.68139081 0.68253596]\n",
      "Mean cross validation test score: 0.6821241551915708\n",
      "Mean cross validation train score: 0.7027360521453098\n",
      "Standard deviation in cv scores: 0.0008868012642297641\n"
     ]
    }
   ],
   "source": [
    "cv_scores_test= cross_val_score(rf,X_test,y_test,cv=5,scoring='roc_auc')\n",
    "cv_scores_train= cross_val_score(rf,X_train,y_train,cv=5,scoring='roc_auc')\n",
    "\n",
    "print(cv_scores_test)\n",
    "\n",
    "cv_scores_rf_test= cv_scores_test.mean()\n",
    "cv_scores_rf_train= cv_scores_train.mean()\n",
    "cv_scores_std_rf= cv_scores_test.std()\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_rf_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_rf_train))\n",
    "print ('Standard deviation in cv scores: ' +str(cv_scores_std_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a7cc3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 128010  447205]\n",
      " [  82704 1100545]]\n",
      "0.6986523465933906\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(subsample=0.8, learning_rate=0.05 , n_estimators=100, random_state=5, max_depth=9, max_leaf_nodes=100)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "#Predict using the model:\n",
    "\n",
    "y_predict_gbc = gbc.predict(X_test)\n",
    "\n",
    "#Confusion matrix:\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict_gbc)\n",
    "print(cnf_matrix)\n",
    "Accuracy_gbc=gbc.score(X_test,y_test)\n",
    "print(Accuracy_gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe658681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69258306 0.69057517 0.69410721 0.69274026 0.69474203]\n",
      "Mean cross validation test score: 0.6929495463454713\n",
      "Mean cross validation train score: 0.6929003184251197\n",
      "Standard deviation in cv scores: 0.0014400681334626522\n"
     ]
    }
   ],
   "source": [
    "cv_scores_test= cross_val_score(gbc,X_test,y_test,cv=5,scoring='roc_auc')\n",
    "cv_scores_train= cross_val_score(gbc,X_train,y_train,cv=5,scoring='roc_auc')\n",
    "\n",
    "print(cv_scores_test)\n",
    "\n",
    "cv_scores_gbc_test= cv_scores_test.mean()\n",
    "cv_scores_gbc_train= cv_scores_train.mean()\n",
    "cv_scores_std_gbc= cv_scores_test.std()\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_gbc_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_gbc_train))\n",
    "print ('Standard deviation in cv scores: ' +str(cv_scores_std_gbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83e5c058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 134675  440540]\n",
      " [  90401 1092848]]\n",
      "0.6980654707744941\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict_lgbm = lgbm.predict(X_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict_lgbm)\n",
    "print(cnf_matrix)\n",
    "Accuracy_lgbm=lgbm.score(X_test,y_test)\n",
    "print(Accuracy_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5aefffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69174668 0.68962431 0.69289536 0.6912938  0.69349087]\n",
      "Mean cross validation test score: 0.6918102031992472\n",
      "Mean cross validation train score: 0.6920108599188091\n",
      "Standard deviation in cv scores: 0.0013454402382618263\n"
     ]
    }
   ],
   "source": [
    "cv_scores_test= cross_val_score(lgbm,X_test,y_test,cv=5,scoring='roc_auc')\n",
    "cv_scores_train= cross_val_score(lgbm,X_train,y_train,cv=5,scoring='roc_auc')\n",
    "\n",
    "print(cv_scores_test)\n",
    "\n",
    "cv_scores_lgbm_test= cv_scores_test.mean()\n",
    "cv_scores_lgbm_train= cv_scores_train.mean()\n",
    "cv_scores_std_lgbm= cv_scores_test.std()\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_lgbm_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_lgbm_train))\n",
    "print ('Standard deviation in cv scores: ' +str(cv_scores_std_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3345d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dcc179d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "The best parameters are: /n {'learning_rate': 0.05, 'max_depth': 10, 'min_data_in_leaf': 25, 'num_iterations': 5000}\n",
      "0.7086032777950576\n"
     ]
    }
   ],
   "source": [
    "#grid search  hyperparameter tuning\n",
    "parameters = {\n",
    "#     'task' : ['predict'],\n",
    "#     'boosting': ['gbdt' ],\n",
    "#     'objective': ['root_mean_squared_error'],\n",
    "     'num_iterations': [  1500, 2000,5000  ],\n",
    "     'learning_rate':[  0.05, 0.005 ],\n",
    "#    'num_leaves':[ 7, 15, 31  ],\n",
    "    'max_depth' :[ 5,10],\n",
    "    'min_data_in_leaf':[15,25 ],\n",
    "#   'feature_fraction': [ 0.6, 0.8,  0.9],\n",
    "#     'bagging_fraction': [  0.6, 0.8 ],\n",
    "#     'bagging_freq': [   100, 200, 400  ],\n",
    "     \n",
    " }\n",
    "\n",
    "gsearch_lgb = GridSearchCV(lgbm, param_grid = parameters, n_jobs=6, verbose=10)\n",
    "model = gsearch_lgb.fit(X_train,y_train)\n",
    " \n",
    "\n",
    "print(\"The best parameters are: /n\",  gsearch_lgb.best_params_)\n",
    "\n",
    "# Store the model for prediction (chapter 5)\n",
    "model = gsearch_lgb.best_estimator_\n",
    "print(gsearch_lgb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbb0ff3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[[ 163478  411737]\n",
      " [  99697 1083552]]\n",
      "0.7091586748434998\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lgbm_best = LGBMClassifier(learning_rate = 0.05, max_depth = 10, min_data_in_leaf = 25, num_iterations = 5000)\n",
    "lgbm_best.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict_lgbm = lgbm_best.predict(X_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict_lgbm)\n",
    "print(cnf_matrix)\n",
    "Accuracy_lgbm=lgbm_best.score(X_test,y_test)\n",
    "print(Accuracy_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06252632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[0.70798909 0.70577142 0.70865416 0.70788279 0.70898313]\n",
      "Mean cross validation test score: 0.7078561191057784\n",
      "Mean cross validation train score: 0.715335696810019\n",
      "Standard deviation in cv scores: 0.001119944493690363\n"
     ]
    }
   ],
   "source": [
    "cv_scores_test= cross_val_score(lgbm_best,X_test,y_test,cv=5,scoring='roc_auc')\n",
    "cv_scores_train= cross_val_score(lgbm_best,X_train,y_train,cv=5,scoring='roc_auc')\n",
    "\n",
    "print(cv_scores_test)\n",
    "\n",
    "cv_scores_lgbm_test= cv_scores_test.mean()\n",
    "cv_scores_lgbm_train= cv_scores_train.mean()\n",
    "cv_scores_std_lgbm= cv_scores_test.std()\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_lgbm_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_lgbm_train))\n",
    "print ('Standard deviation in cv scores: ' +str(cv_scores_std_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e271ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paramGrid = {\"max_depth\":[5,10],\n",
    " #           \"colsample_bytree\":[0.3,0.4]}  \n",
    "\n",
    "\n",
    "#lgbm = LGBMClassifier(objective='binary', num_boost_round=10)\n",
    "\n",
    "#gs = GridSearchCV(lgbm, paramGrid, cv=3, verbose=2, n_jobs=1)\n",
    "\n",
    "\n",
    "#model = gs.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "#print(\"The best parameters are: /n\",  gs.best_params_)\n",
    "\n",
    "# Store the model for prediction (chapter 5)\n",
    "#model = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f66112db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Algorithm  Model accuracy score\n",
      "0               LGBM              0.709159\n",
      "1      Random Forest              0.703924\n",
      "2  Gradient Boosting              0.698652\n",
      "\n",
      "\n",
      "           Algorithm  ROC-AUC train score  ROC-AUC test score\n",
      "0               LGBM             0.715336            0.707856\n",
      "1      Random Forest             0.702736            0.682124\n",
      "2  Gradient Boosting             0.692950            0.692950\n"
     ]
    }
   ],
   "source": [
    "m_Labels = ['LGBM','Random Forest', 'Gradient Boosting']\n",
    "scores_test = [cv_scores_lgbm_test, cv_scores_rf_test, cv_scores_gbc_test]\n",
    "scores_train = [cv_scores_lgbm_train, cv_scores_rf_train, cv_scores_gbc_test]\n",
    "accuracies = [Accuracy_lgbm, Accuracy_rf, Accuracy_gbc]\n",
    "\n",
    "score_tab_acc = pd.DataFrame(list(zip(m_Labels, accuracies)), \n",
    "               columns =['Algorithm', 'Model accuracy score']) \n",
    "\n",
    "score_tab = pd.DataFrame(list(zip(m_Labels, scores_train, scores_test)), \n",
    "               columns =['Algorithm', 'ROC-AUC train score', 'ROC-AUC test score' ]) \n",
    "\n",
    "print(score_tab_acc)\n",
    "print(\"\\n\")\n",
    "print(score_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ccec2c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Features  Importance scores\n",
      "0              Unnamed: 0                  0\n",
      "1                 user_id               8815\n",
      "2                eval_set              12036\n",
      "3               order_dow              12601\n",
      "4       order_hour_of_day              14472\n",
      "5  days_since_prior_order              15528\n",
      "6              product_id              18244\n",
      "7       add_to_cart_order              19833\n",
      "8                aisle_id              22745\n",
      "9           department_id              25726\n"
     ]
    }
   ],
   "source": [
    "lgbm_importances = list(lgbm_best.feature_importances_)\n",
    "imp=np.sort(lgbm_importances)\n",
    "table=pd.DataFrame(list(zip(order_total,imp)),columns =['Features', 'Importance scores']) \n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f9843df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Features  Importance scores\n",
      "0              Unnamed: 0           0.000000\n",
      "1                 user_id           0.058767\n",
      "2                eval_set           0.080240\n",
      "3               order_dow           0.084007\n",
      "4       order_hour_of_day           0.096480\n",
      "5  days_since_prior_order           0.103520\n",
      "6              product_id           0.121627\n",
      "7       add_to_cart_order           0.132220\n",
      "8                aisle_id           0.151633\n",
      "9           department_id           0.171507\n"
     ]
    }
   ],
   "source": [
    "sum_lgbm = sum(lgbm_importances)\n",
    "percentages = lgbm_importances / sum_lgbm\n",
    "table['Importance scores'] = table['Importance scores'] / sum_lgbm\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5faec93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Features  Importance scores\n",
      "0              Unnamed: 0           0.000000\n",
      "1                 user_id           0.001423\n",
      "2                eval_set           0.005301\n",
      "3               order_dow           0.007436\n",
      "4       order_hour_of_day           0.011417\n",
      "5  days_since_prior_order           0.059939\n",
      "6              product_id           0.152800\n",
      "7       add_to_cart_order           0.158253\n",
      "8                aisle_id           0.258121\n",
      "9           department_id           0.345309\n"
     ]
    }
   ],
   "source": [
    "importances = list(gbc.feature_importances_)\n",
    "imp=np.sort(importances)\n",
    "table=pd.DataFrame(list(zip(order_total,imp)),columns =['Features', 'Importance scores']) \n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4210c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Features  Importance scores\n",
      "0              Unnamed: 0           0.000000\n",
      "1                 user_id           0.032358\n",
      "2                eval_set           0.047516\n",
      "3               order_dow           0.069548\n",
      "4       order_hour_of_day           0.077645\n",
      "5  days_since_prior_order           0.082274\n",
      "6              product_id           0.107432\n",
      "7       add_to_cart_order           0.172446\n",
      "8                aisle_id           0.201412\n",
      "9           department_id           0.209367\n"
     ]
    }
   ],
   "source": [
    "importances = list(rf.feature_importances_)\n",
    "imp=np.sort(importances)\n",
    "table=pd.DataFrame(list(zip(order_total,imp)),columns =['Features', 'Importance scores']) \n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f463a6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM score:  0.8090622570969686\n",
      "GBC score:  0.8059651431582363\n",
      "Rf score:  0.8009531816240713\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"LGBM score: \", f1_score(y_test,y_predict_lgbm))\n",
    "print(\"GBC score: \", f1_score(y_test,y_predict_gbc))\n",
    "print(\"Rf score: \", f1_score(y_test,y_predict_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
