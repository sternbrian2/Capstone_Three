{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7efba373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a051a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "\n",
    "order_total = pd.read_csv('order_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0049b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#order_total.head()\n",
    "order_total = order_total.drop(columns = ['product_name','aisle','department','order_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f892d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = order_total['reordered']\n",
    "order_total = order_total.drop(columns = ['reordered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "969661c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "def Labelencoder_feature(x):\n",
    "    le=LabelEncoder()\n",
    "    x=le.fit_transform(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e2659eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_total=order_total.apply(Labelencoder_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fac2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17b401ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b4483c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(order_total, target, test_size=0.2, random_state=42)\n",
    "scaler_x = MinMaxScaler((-1,1))\n",
    "X_train = scaler_x.fit_transform(X_train)\n",
    "X_test = scaler_x.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcbc866d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_parameter</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.674271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.674186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.674169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.674168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.674168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.674168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_parameter  Accuracy\n",
       "0        0.001  0.674271\n",
       "1        0.010  0.674186\n",
       "2        0.100  0.674169\n",
       "3        1.000  0.674168\n",
       "4       10.000  0.674168\n",
       "5      100.000  0.674168"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear Regression\n",
    "\n",
    "C_param_range = [0.001,0.01,0.1,1,10,100]\n",
    "\n",
    "table = pd.DataFrame(columns = ['C_parameter','Accuracy'])\n",
    "table['C_parameter'] = C_param_range\n",
    "\n",
    "j = 0\n",
    "for i in C_param_range:\n",
    "    \n",
    "    # Apply logistic regression model to training data\n",
    "    Logreg = LogisticRegression(penalty = 'l2', C = i,random_state = 42)\n",
    "    Logreg.fit(X_train,y_train)\n",
    "    \n",
    "    # Predict using model\n",
    "    y_pred_lr = Logreg.predict(X_test)\n",
    "    \n",
    "    # Saving accuracy score in table\n",
    "    table.iloc[j,1] = accuracy_score(y_test,y_pred_lr)\n",
    "    j += 1\n",
    "    \n",
    "table   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b03f6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 185996  389219]\n",
      " [ 118372 1064877]]\n",
      "0.7113441048551463\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(bootstrap=True,n_estimators=100,criterion='entropy')\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict_rf = rf.predict(X_test)\n",
    "\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict_rf)\n",
    "print(cnf_matrix)\n",
    "Accuracy_rf=rf.score(X_test,y_test)\n",
    "print(Accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23bcf160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68747625 0.685962   0.68890373 0.68716853 0.68866613]\n",
      "Mean cross validation test score: 0.687635329474371\n",
      "Mean cross validation train score: 0.7115159881232627\n",
      "Standard deviation in cv scores: 0.0010690764699199384\n"
     ]
    }
   ],
   "source": [
    "cv_scores_test= cross_val_score(rf,X_test,y_test,cv=5,scoring='roc_auc')\n",
    "cv_scores_train= cross_val_score(rf,X_train,y_train,cv=5,scoring='roc_auc')\n",
    "\n",
    "print(cv_scores_test)\n",
    "\n",
    "cv_scores_rf_test= cv_scores_test.mean()\n",
    "cv_scores_rf_train= cv_scores_train.mean()\n",
    "cv_scores_std_rf= cv_scores_test.std()\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_rf_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_rf_train))\n",
    "print ('Standard deviation in cv scores: ' +str(cv_scores_std_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a7cc3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 127605  447610]\n",
      " [  82387 1100862]]\n",
      "0.698602302918911\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(subsample=0.8, learning_rate=0.05 , n_estimators=100, random_state=5, max_depth=9, max_leaf_nodes=100)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "#Predict using the model:\n",
    "\n",
    "y_predict_gbc = gbc.predict(X_test)\n",
    "\n",
    "#Confusion matrix:\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict_gbc)\n",
    "print(cnf_matrix)\n",
    "Accuracy_gbc=gbc.score(X_test,y_test)\n",
    "print(Accuracy_gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe658681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69247512 0.69089277 0.69386518 0.69240941 0.69500198]\n",
      "Mean cross validation test score: 0.6929288928818007\n",
      "Mean cross validation train score: 0.6928309334876651\n",
      "Standard deviation in cv scores: 0.001399706371051728\n"
     ]
    }
   ],
   "source": [
    "cv_scores_test= cross_val_score(gbc,X_test,y_test,cv=5,scoring='roc_auc')\n",
    "cv_scores_train= cross_val_score(gbc,X_train,y_train,cv=5,scoring='roc_auc')\n",
    "\n",
    "print(cv_scores_test)\n",
    "\n",
    "cv_scores_gbc_test= cv_scores_test.mean()\n",
    "cv_scores_gbc_train= cv_scores_train.mean()\n",
    "cv_scores_std_gbc= cv_scores_test.std()\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_gbc_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_gbc_train))\n",
    "print ('Standard deviation in cv scores: ' +str(cv_scores_std_gbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83e5c058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 134717  440498]\n",
      " [  90697 1092552]]\n",
      "0.6979210265322463\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict_lgbm = lgbm.predict(X_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict_lgbm)\n",
    "print(cnf_matrix)\n",
    "Accuracy_lgbm=lgbm.score(X_test,y_test)\n",
    "print(Accuracy_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5aefffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69180659 0.68956735 0.69291551 0.69111131 0.69341022]\n",
      "Mean cross validation test score: 0.6917621977186125\n",
      "Mean cross validation train score: 0.6919790483603427\n",
      "Standard deviation in cv scores: 0.001363019671961549\n"
     ]
    }
   ],
   "source": [
    "cv_scores_test= cross_val_score(lgbm,X_test,y_test,cv=5,scoring='roc_auc')\n",
    "cv_scores_train= cross_val_score(lgbm,X_train,y_train,cv=5,scoring='roc_auc')\n",
    "\n",
    "print(cv_scores_test)\n",
    "\n",
    "cv_scores_lgbm_test= cv_scores_test.mean()\n",
    "cv_scores_lgbm_train= cv_scores_train.mean()\n",
    "cv_scores_std_lgbm= cv_scores_test.std()\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_lgbm_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_lgbm_train))\n",
    "print ('Standard deviation in cv scores: ' +str(cv_scores_std_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3345d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dcc179d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "The best parameters are: /n {'learning_rate': 0.05, 'max_depth': 10, 'min_data_in_leaf': 15, 'num_iterations': 5000}\n",
      "0.7101054414836303\n"
     ]
    }
   ],
   "source": [
    "#grid search  hyperparameter tuning\n",
    "parameters = {\n",
    "#     'task' : ['predict'],\n",
    "#     'boosting': ['gbdt' ],\n",
    "#     'objective': ['root_mean_squared_error'],\n",
    "     'num_iterations': [  1500, 2000,5000  ],\n",
    "     'learning_rate':[  0.05, 0.005 ],\n",
    "#    'num_leaves':[ 7, 15, 31  ],\n",
    "    'max_depth' :[ 5,10],\n",
    "    'min_data_in_leaf':[15,25 ],\n",
    "#   'feature_fraction': [ 0.6, 0.8,  0.9],\n",
    "#     'bagging_fraction': [  0.6, 0.8 ],\n",
    "#     'bagging_freq': [   100, 200, 400  ],\n",
    "     \n",
    " }\n",
    "\n",
    "gsearch_lgb = GridSearchCV(lgbm, param_grid = parameters, n_jobs=6, verbose=10)\n",
    "model = gsearch_lgb.fit(X_train,y_train)\n",
    " \n",
    "\n",
    "print(\"The best parameters are: /n\",  gsearch_lgb.best_params_)\n",
    "\n",
    "# Store the model for prediction (chapter 5)\n",
    "model = gsearch_lgb.best_estimator_\n",
    "print(gsearch_lgb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbb0ff3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 164084  411131]\n",
      " [  97361 1085888]]\n",
      "0.7108317258698501\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lgbm_best = LGBMClassifier(learning_rate = 0.05, max_depth = 10, min_data_in_leaf = 15, num_iterations = 5000)\n",
    "lgbm_best.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict_lgbm = lgbm_best.predict(X_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict_lgbm)\n",
    "print(cnf_matrix)\n",
    "Accuracy_lgbm=lgbm_best.score(X_test,y_test)\n",
    "print(Accuracy_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06252632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[0.70818203 0.70601122 0.70906805 0.7082577  0.70904284]\n",
      "Mean cross validation test score: 0.7081123685070299\n",
      "Mean cross validation train score: 0.7170377015586624\n",
      "Standard deviation in cv scores: 0.001115337340181254\n"
     ]
    }
   ],
   "source": [
    "cv_scores_test= cross_val_score(lgbm_best,X_test,y_test,cv=5,scoring='roc_auc')\n",
    "cv_scores_train= cross_val_score(lgbm_best,X_train,y_train,cv=5,scoring='roc_auc')\n",
    "\n",
    "print(cv_scores_test)\n",
    "\n",
    "cv_scores_lgbm_test= cv_scores_test.mean()\n",
    "cv_scores_lgbm_train= cv_scores_train.mean()\n",
    "cv_scores_std_lgbm= cv_scores_test.std()\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_lgbm_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_lgbm_train))\n",
    "print ('Standard deviation in cv scores: ' +str(cv_scores_std_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e271ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paramGrid = {\"max_depth\":[5,10],\n",
    " #           \"colsample_bytree\":[0.3,0.4]}  \n",
    "\n",
    "\n",
    "#lgbm = LGBMClassifier(objective='binary', num_boost_round=10)\n",
    "\n",
    "#gs = GridSearchCV(lgbm, paramGrid, cv=3, verbose=2, n_jobs=1)\n",
    "\n",
    "\n",
    "#model = gs.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "#print(\"The best parameters are: /n\",  gs.best_params_)\n",
    "\n",
    "# Store the model for prediction (chapter 5)\n",
    "#model = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f66112db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Algorithm  Model accuracy score\n",
      "0               LGBM              0.710832\n",
      "1      Random Forest              0.711344\n",
      "2  Gradient Boosting              0.698602\n",
      "\n",
      "\n",
      "           Algorithm  ROC-AUC train score  ROC-AUC test score\n",
      "0               LGBM             0.717038            0.708112\n",
      "1      Random Forest             0.711516            0.687635\n",
      "2  Gradient Boosting             0.692929            0.692929\n"
     ]
    }
   ],
   "source": [
    "m_Labels = ['LGBM','Random Forest', 'Gradient Boosting']\n",
    "scores_test = [cv_scores_lgbm_test, cv_scores_rf_test, cv_scores_gbc_test]\n",
    "scores_train = [cv_scores_lgbm_train, cv_scores_rf_train, cv_scores_gbc_test]\n",
    "accuracies = [Accuracy_lgbm, Accuracy_rf, Accuracy_gbc]\n",
    "\n",
    "score_tab_acc = pd.DataFrame(list(zip(m_Labels, accuracies)), \n",
    "               columns =['Algorithm', 'Model accuracy score']) \n",
    "\n",
    "score_tab = pd.DataFrame(list(zip(m_Labels, scores_train, scores_test)), \n",
    "               columns =['Algorithm', 'ROC-AUC train score', 'ROC-AUC test score' ]) \n",
    "\n",
    "print(score_tab_acc)\n",
    "print(\"\\n\")\n",
    "print(score_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccec2c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Features  Importance scores\n",
      "0               Unnamed: 0                  0\n",
      "1                 order_id               8043\n",
      "2                  user_id              10091\n",
      "3                 eval_set              10441\n",
      "4                order_dow              12724\n",
      "5        order_hour_of_day              14018\n",
      "6   days_since_prior_order              16446\n",
      "7               product_id              18308\n",
      "8        add_to_cart_order              19196\n",
      "9                 aisle_id              20258\n",
      "10           department_id              20475\n"
     ]
    }
   ],
   "source": [
    "lgbm_importances = list(lgbm_best.feature_importances_)\n",
    "imp=np.sort(lgbm_importances)\n",
    "table=pd.DataFrame(list(zip(order_total,imp)),columns =['Features', 'Importance scores']) \n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f9843df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Features  Importance scores\n",
      "0               Unnamed: 0           0.000000\n",
      "1                 order_id           0.053620\n",
      "2                  user_id           0.067273\n",
      "3                 eval_set           0.069607\n",
      "4                order_dow           0.084827\n",
      "5        order_hour_of_day           0.093453\n",
      "6   days_since_prior_order           0.109640\n",
      "7               product_id           0.122053\n",
      "8        add_to_cart_order           0.127973\n",
      "9                 aisle_id           0.135053\n",
      "10           department_id           0.136500\n"
     ]
    }
   ],
   "source": [
    "sum_lgbm = sum(lgbm_importances)\n",
    "percentages = lgbm_importances / sum_lgbm\n",
    "table['Importance scores'] = table['Importance scores'] / sum_lgbm\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5faec93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Features  Importance scores\n",
      "0               Unnamed: 0           0.000000\n",
      "1                 order_id           0.001169\n",
      "2                  user_id           0.001170\n",
      "3                 eval_set           0.005205\n",
      "4                order_dow           0.007343\n",
      "5        order_hour_of_day           0.011401\n",
      "6   days_since_prior_order           0.060910\n",
      "7               product_id           0.152199\n",
      "8        add_to_cart_order           0.158120\n",
      "9                 aisle_id           0.257882\n",
      "10           department_id           0.344601\n"
     ]
    }
   ],
   "source": [
    "importances = list(gbc.feature_importances_)\n",
    "imp=np.sort(importances)\n",
    "table=pd.DataFrame(list(zip(order_total,imp)),columns =['Features', 'Importance scores']) \n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4210c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Features  Importance scores\n",
      "0               Unnamed: 0           0.000000\n",
      "1                 order_id           0.032596\n",
      "2                  user_id           0.045789\n",
      "3                 eval_set           0.058179\n",
      "4                order_dow           0.070273\n",
      "5        order_hour_of_day           0.071638\n",
      "6   days_since_prior_order           0.087990\n",
      "7               product_id           0.141017\n",
      "8        add_to_cart_order           0.156486\n",
      "9                 aisle_id           0.162876\n",
      "10           department_id           0.173155\n"
     ]
    }
   ],
   "source": [
    "importances = list(rf.feature_importances_)\n",
    "imp=np.sort(importances)\n",
    "table=pd.DataFrame(list(zip(order_total,imp)),columns =['Features', 'Importance scores']) \n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f463a6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM score:  0.8102831507893986\n",
      "GBC score:  0.805984212882648\n",
      "Rf score:  0.8075371254045262\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"LGBM score: \", f1_score(y_test,y_predict_lgbm))\n",
    "print(\"GBC score: \", f1_score(y_test,y_predict_gbc))\n",
    "print(\"Rf score: \", f1_score(y_test,y_predict_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
