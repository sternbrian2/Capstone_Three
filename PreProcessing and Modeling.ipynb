{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7efba373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a051a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "\n",
    "order_total = pd.read_csv('order_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0049b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#order_total.head()\n",
    "order_total = order_total.drop(columns = ['product_name','aisle','department'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f892d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = order_total['reordered']\n",
    "order_total = order_total.drop(columns = ['reordered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "969661c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "def Labelencoder_feature(x):\n",
    "    le=LabelEncoder()\n",
    "    x=le.fit_transform(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e2659eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_total=order_total.apply(Labelencoder_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fac2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17b401ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b4483c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(order_total, target, test_size=0.2, random_state=42)\n",
    "scaler_x = MinMaxScaler((-1,1))\n",
    "X_train = scaler_x.fit_transform(X_train)\n",
    "X_test = scaler_x.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcbc866d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_parameter</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.705246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.705353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.705378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.705382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.705383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.705382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_parameter  Accuracy\n",
       "0        0.001  0.705246\n",
       "1        0.010  0.705353\n",
       "2        0.100  0.705378\n",
       "3        1.000  0.705382\n",
       "4       10.000  0.705383\n",
       "5      100.000  0.705382"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear Regression\n",
    "\n",
    "C_param_range = [0.001,0.01,0.1,1,10,100]\n",
    "\n",
    "table = pd.DataFrame(columns = ['C_parameter','Accuracy'])\n",
    "table['C_parameter'] = C_param_range\n",
    "\n",
    "j = 0\n",
    "for i in C_param_range:\n",
    "    \n",
    "    # Apply logistic regression model to training data\n",
    "    Logreg = LogisticRegression(penalty = 'l2', C = i,random_state = 42)\n",
    "    Logreg.fit(X_train,y_train)\n",
    "    \n",
    "    # Predict using model\n",
    "    y_pred_lr = Logreg.predict(X_test)\n",
    "    \n",
    "    # Saving accuracy score in table\n",
    "    table.iloc[j,1] = accuracy_score(y_test,y_pred_lr)\n",
    "    j += 1\n",
    "    \n",
    "table   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b03f6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 266568  308647]\n",
      " [  99457 1083792]]\n",
      "0.7679201848886301\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(bootstrap=True,n_estimators=100,criterion='entropy')\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict_rf = rf.predict(X_test)\n",
    "\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict_rf)\n",
    "print(cnf_matrix)\n",
    "Accuracy_rf=rf.score(X_test,y_test)\n",
    "print(Accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23bcf160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77598613 0.77688362 0.77851716 0.77660452 0.7786397 ]\n",
      "Mean cross validation test score: 0.7773262241401726\n",
      "Mean cross validation train score: 0.795390733152289\n",
      "Standard deviation in cv scores: 0.0010635947514436753\n"
     ]
    }
   ],
   "source": [
    "cv_scores_test= cross_val_score(rf,X_test,y_test,cv=5,scoring='roc_auc')\n",
    "cv_scores_train= cross_val_score(rf,X_train,y_train,cv=5,scoring='roc_auc')\n",
    "\n",
    "print(cv_scores_test)\n",
    "\n",
    "cv_scores_rf_test= cv_scores_test.mean()\n",
    "cv_scores_rf_train= cv_scores_train.mean()\n",
    "cv_scores_std_rf= cv_scores_test.std()\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_rf_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_rf_train))\n",
    "print ('Standard deviation in cv scores: ' +str(cv_scores_std_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a7cc3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 234940  340275]\n",
      " [  89260 1093989]]\n",
      "0.7557328441185034\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(subsample=0.8, learning_rate=0.05 , n_estimators=100, random_state=5, max_depth=9, max_leaf_nodes=100)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "#Predict using the model:\n",
    "\n",
    "y_predict_gbc = gbc.predict(X_test)\n",
    "\n",
    "#Confusion matrix:\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict_gbc)\n",
    "print(cnf_matrix)\n",
    "Accuracy_gbc=gbc.score(X_test,y_test)\n",
    "print(Accuracy_gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe658681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77696562 0.7771163  0.7785517  0.77759421 0.78005489]\n",
      "Mean cross validation test score: 0.7780565456403374\n",
      "Mean cross validation train score: 0.7782898192799717\n",
      "Standard deviation in cv scores: 0.0011424966277863398\n"
     ]
    }
   ],
   "source": [
    "cv_scores_test= cross_val_score(gbc,X_test,y_test,cv=5,scoring='roc_auc')\n",
    "cv_scores_train= cross_val_score(gbc,X_train,y_train,cv=5,scoring='roc_auc')\n",
    "\n",
    "print(cv_scores_test)\n",
    "\n",
    "cv_scores_gbc_test= cv_scores_test.mean()\n",
    "cv_scores_gbc_train= cv_scores_train.mean()\n",
    "cv_scores_std_gbc= cv_scores_test.std()\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_gbc_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_gbc_train))\n",
    "print ('Standard deviation in cv scores: ' +str(cv_scores_std_gbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83e5c058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 238716  336499]\n",
      " [  92103 1091146]]\n",
      "0.7562634208036104\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict_lgbm = lgbm.predict(X_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict_lgbm)\n",
    "print(cnf_matrix)\n",
    "Accuracy_lgbm=lgbm.score(X_test,y_test)\n",
    "print(Accuracy_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5aefffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77758338 0.77761489 0.77880001 0.77818276 0.78038659]\n",
      "Mean cross validation test score: 0.7785135252646231\n",
      "Mean cross validation train score: 0.7790891940491722\n",
      "Standard deviation in cv scores: 0.0010365859088685163\n"
     ]
    }
   ],
   "source": [
    "cv_scores_test= cross_val_score(lgbm,X_test,y_test,cv=5,scoring='roc_auc')\n",
    "cv_scores_train= cross_val_score(lgbm,X_train,y_train,cv=5,scoring='roc_auc')\n",
    "\n",
    "print(cv_scores_test)\n",
    "\n",
    "cv_scores_lgbm_test= cv_scores_test.mean()\n",
    "cv_scores_lgbm_train= cv_scores_train.mean()\n",
    "cv_scores_std_lgbm= cv_scores_test.std()\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_lgbm_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_lgbm_train))\n",
    "print ('Standard deviation in cv scores: ' +str(cv_scores_std_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dcc179d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stern\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\stern\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] num_iterations is set=1500, num_boost_round=10 will be ignored. Current value: num_iterations=1500\n",
      "The best parameters are: /n {'learning_rate': 0.05, 'max_depth': 5, 'min_data_in_leaf': 15, 'num_iterations': 1500}\n",
      "0.7516102789190134\n"
     ]
    }
   ],
   "source": [
    "#grid search  hyperparameter tuning\n",
    "parameters = {\n",
    "#     'task' : ['predict'],\n",
    "#     'boosting': ['gbdt' ],\n",
    "#     'objective': ['root_mean_squared_error'],\n",
    "     'num_iterations': [  1500, 2000,5000  ],\n",
    "     'learning_rate':[  0.05, 0.005 ],\n",
    "#    'num_leaves':[ 7, 15, 31  ],\n",
    "    'max_depth' :[ 5,10],\n",
    "    'min_data_in_leaf':[15,25 ],\n",
    "#   'feature_fraction': [ 0.6, 0.8,  0.9],\n",
    "#     'bagging_fraction': [  0.6, 0.8 ],\n",
    "#     'bagging_freq': [   100, 200, 400  ],\n",
    "     \n",
    " }\n",
    "\n",
    "gsearch_lgb = GridSearchCV(lgbm, param_grid = parameters, n_jobs=6, verbose=10)\n",
    "model = gsearch_lgb.fit(X_train,y_train)\n",
    " \n",
    "\n",
    "print(\"The best parameters are: /n\",  gsearch_lgb.best_params_)\n",
    "\n",
    "# Store the model for prediction (chapter 5)\n",
    "model = gsearch_lgb.best_estimator_\n",
    "print(gsearch_lgb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbb0ff3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stern\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[[ 248189  327026]\n",
      " [  95372 1087877]]\n",
      "0.7597914998544184\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lgbm_best = LGBMClassifier(learning_rate = 0.05, max_depth = 5, min_data_in_leaf = 15, num_iterations = 1500)\n",
    "lgbm_best.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict_lgbm = lgbm_best.predict(X_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict_lgbm)\n",
    "print(cnf_matrix)\n",
    "Accuracy_lgbm=lgbm_best.score(X_test,y_test)\n",
    "print(Accuracy_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06252632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stern\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stern\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stern\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stern\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stern\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stern\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stern\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stern\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stern\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stern\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[0.78523854 0.78502068 0.78636645 0.7861716  0.78784202]\n",
      "Mean cross validation test score: 0.7861278613373788\n",
      "Mean cross validation train score: 0.7883425896100268\n",
      "Standard deviation in cv scores: 0.001001392226219488\n"
     ]
    }
   ],
   "source": [
    "cv_scores_test= cross_val_score(lgbm_best,X_test,y_test,cv=5,scoring='roc_auc')\n",
    "cv_scores_train= cross_val_score(lgbm_best,X_train,y_train,cv=5,scoring='roc_auc')\n",
    "\n",
    "print(cv_scores_test)\n",
    "\n",
    "cv_scores_lgbm_test= cv_scores_test.mean()\n",
    "cv_scores_lgbm_train= cv_scores_train.mean()\n",
    "cv_scores_std_lgbm= cv_scores_test.std()\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_lgbm_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_lgbm_train))\n",
    "print ('Standard deviation in cv scores: ' +str(cv_scores_std_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e271ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paramGrid = {\"max_depth\":[5,10],\n",
    " #           \"colsample_bytree\":[0.3,0.4]}  \n",
    "\n",
    "\n",
    "#lgbm = LGBMClassifier(objective='binary', num_boost_round=10)\n",
    "\n",
    "#gs = GridSearchCV(lgbm, paramGrid, cv=3, verbose=2, n_jobs=1)\n",
    "\n",
    "\n",
    "#model = gs.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "#print(\"The best parameters are: /n\",  gs.best_params_)\n",
    "\n",
    "# Store the model for prediction (chapter 5)\n",
    "#model = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f66112db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Algorithm  Model accuracy score\n",
      "0               LGBM              0.759791\n",
      "1      Random Forest              0.767920\n",
      "2  Gradient Boosting              0.755733\n",
      "\n",
      "\n",
      "           Algorithm  ROC-AUC train score  ROC-AUC test score\n",
      "0               LGBM             0.788343            0.786128\n",
      "1      Random Forest             0.795391            0.777326\n",
      "2  Gradient Boosting             0.778057            0.778057\n"
     ]
    }
   ],
   "source": [
    "m_Labels = ['LGBM','Random Forest', 'Gradient Boosting']\n",
    "scores_test = [cv_scores_lgbm_test, cv_scores_rf_test, cv_scores_gbc_test]\n",
    "scores_train = [cv_scores_lgbm_train, cv_scores_rf_train, cv_scores_gbc_test]\n",
    "accuracies = [Accuracy_lgbm, Accuracy_rf, Accuracy_gbc]\n",
    "\n",
    "score_tab_acc = pd.DataFrame(list(zip(m_Labels, accuracies)), \n",
    "               columns =['Algorithm', 'Model accuracy score']) \n",
    "\n",
    "score_tab = pd.DataFrame(list(zip(m_Labels, scores_train, scores_test)), \n",
    "               columns =['Algorithm', 'ROC-AUC train score', 'ROC-AUC test score' ]) \n",
    "\n",
    "print(score_tab_acc)\n",
    "print(\"\\n\")\n",
    "print(score_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccec2c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Features  Importance scores\n",
      "0               Unnamed: 0                  0\n",
      "1                 order_id               1072\n",
      "2                  user_id               1944\n",
      "3                 eval_set               2279\n",
      "4             order_number               2986\n",
      "5                order_dow               3400\n",
      "6        order_hour_of_day               3435\n",
      "7   days_since_prior_order               3588\n",
      "8               product_id               3700\n",
      "9        add_to_cart_order               4584\n",
      "10                aisle_id               8419\n",
      "11           department_id               8499\n"
     ]
    }
   ],
   "source": [
    "lgbm_importances = list(lgbm_best.feature_importances_)\n",
    "imp=np.sort(importances)\n",
    "table=pd.DataFrame(list(zip(order_total,imp)),columns =['Features', 'Importance scores']) \n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f9843df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Features  Importance scores\n",
      "0               Unnamed: 0           0.000000\n",
      "1                 order_id           0.024416\n",
      "2                  user_id           0.044276\n",
      "3                 eval_set           0.051906\n",
      "4             order_number           0.068009\n",
      "5                order_dow           0.077438\n",
      "6        order_hour_of_day           0.078235\n",
      "7   days_since_prior_order           0.081720\n",
      "8               product_id           0.084271\n",
      "9        add_to_cart_order           0.104405\n",
      "10                aisle_id           0.191751\n",
      "11           department_id           0.193573\n"
     ]
    }
   ],
   "source": [
    "sum_lgbm = sum(lgbm_importances)\n",
    "percentages = lgbm_importances / sum_lgbm\n",
    "table['Importance scores'] = table['Importance scores'] / sum_lgbm\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5faec93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Features  Importance scores\n",
      "0               Unnamed: 0           0.000000\n",
      "1                 order_id           0.000079\n",
      "2                  user_id           0.000133\n",
      "3                 eval_set           0.000642\n",
      "4             order_number           0.000652\n",
      "5                order_dow           0.001827\n",
      "6        order_hour_of_day           0.019695\n",
      "7   days_since_prior_order           0.031294\n",
      "8               product_id           0.067394\n",
      "9        add_to_cart_order           0.078385\n",
      "10                aisle_id           0.141282\n",
      "11           department_id           0.658618\n"
     ]
    }
   ],
   "source": [
    "importances = list(gbc.feature_importances_)\n",
    "imp=np.sort(importances)\n",
    "table=pd.DataFrame(list(zip(order_total,imp)),columns =['Features', 'Importance scores']) \n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4210c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Features  Importance scores\n",
      "0               Unnamed: 0           0.000000\n",
      "1                 order_id           0.036849\n",
      "2                  user_id           0.047058\n",
      "3                 eval_set           0.049744\n",
      "4             order_number           0.065573\n",
      "5                order_dow           0.067067\n",
      "6        order_hour_of_day           0.072756\n",
      "7   days_since_prior_order           0.113658\n",
      "8               product_id           0.116192\n",
      "9        add_to_cart_order           0.120472\n",
      "10                aisle_id           0.125124\n",
      "11           department_id           0.185507\n"
     ]
    }
   ],
   "source": [
    "importances = list(rf.feature_importances_)\n",
    "imp=np.sort(importances)\n",
    "table=pd.DataFrame(list(zip(order_total,imp)),columns =['Features', 'Importance scores']) \n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f463a6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM score:  0.8374236765208501\n",
      "GBC score:  0.8358995733736565\n",
      "Rf score:  0.8415553436596357\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"LGBM score: \", f1_score(y_test,y_predict_lgbm))\n",
    "print(\"GBC score: \", f1_score(y_test,y_predict_gbc))\n",
    "print(\"Rf score: \", f1_score(y_test,y_predict_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
